\chapter{Méthodologie}

\newtheorem{hypo}{Hypothèse}
\newcommand{\newhyp}[2]{%
    \begin{restatable}{hypothesis}{#1}
        \label{hyp:#1}#2
    \end{restatable}%
}

\section{Hypothèses}

\newhyp{contributionguidelines}{%
    les projets possédant des instructions de contribution (fichier type "\en{CONTRIBUTING.md}" ou section
    type "\en{Contributing}" dans le \en{README}) sont plus accessibles pour les nouveaux contributeurs que
    ceux n'en ayant pas \sideparencite[][voir][p.~11]{signals-2019}.%
}

\newhyp{recentcontributorcount}{%
    le nombre de contributeurs uniques récents (du premier janvier 2019 au premier juin 2019) d'un projet
    influe sur son accessibilité pour les nouveaux contributeurs \parencite[voir][p.~12-13,16]{signals-2019}.%
}

\newhyp{recentcommitcount}{%
    le nombre de \englpl{commit} récents (du premier janvier 2019 au premier juin 2019) au sein d'un projet
    influe sur son accessibilité pour les nouveaux contributeurs \parencite[voir][p.~13,16]{signals-2019}.
}

\section{Mesure de l'accessibilité choisie}

La variable mesurée pour représenter l'accessibilité d'un projet pour les nouveaux contributeurs est le nombre
de contributeurs ayant fait leur toute première contribution au projet entre le premier juin 2019 et le
premier septembre 2019. (voir section \ref{sec:accessibility-measure} p.~\pageref{sec:accessibility-measure},
ainsi que \textcite[][p.~13,16]{signals-2019})

\section{Constitution de l'échantillon}

L'échantillon de départ est constitué de la totalité des projets archivés dans le graphe de Software Heritage.
Plusieurs critères d'exclusion ont ensuite été appliqués :

\begin{itemize}
    \item quand deux projets ou plus ont des \englpl{commit} en commun, seul celui qui a reçu le plus
        d'activité (mesuré en regardant le nombre de \englpl{commit} entre le premier et le dernier) a été
        retenu ;
    \item les projets n'ayant enregistré aucune activité (aucun commit) entre le 1er juin 2019 et le 1er
        septembre 2019 n'ont pas été retenus ;
    \item les projets ayant vu moins de deux contributeurs uniques récents (du premier janvier 2019 au premier
        juin 2019) n'ont pas été retenus \sideparencite[][voir][]{mining-github-2014}.
\end{itemize}

\section{Collecte initiale des données}

\todo[inline]{Retravailler cette description.}

Le code (une classe Java) est disponible en annexe \ref{app:collect.java}.

Le graphe est dirigé (un arc d'un nœud A vers B tous signifie que B est un \engl{commit} \emph{parent} de A)
mais l'API fourni aussi des méthodes donnant accès au symmétrique de chaque arc, ce qui permet d'utiliser au
besoin sur le graphe à la fois les algorithmes spécifiques aux graphes orientés et ceux spécifiques aux
graphes non-orientés.

Dans un premier temps, la fonction \texttt{discoverProject} est appelée sur tous les nœuds de type
\texttt{ORI} (point de départ de l'archivage d'un projet par Software Heritage), cette fonction identifie tous
les projets étant des \en{fork} de celui-ci via un double parcours largeur sur la composante connexe du nœud
de départ formée par le sous-graphe des nœuds \texttt{REV} (\en{revision}, terme générique pour les
\englpl{commit}) et \texttt{SNP} (\en{snapshot}, le point d'entrée d'\emph{un} archivage du projet). Cette
détection se fait en deux parcours largeur au lieu d'un seul afin de calculer en même temps la taille de la
plus longue chaîne de commits accessible depuis chaque nœud \texttt{ORI} de la composante connexe (donc depuis
chaque fork du projet initial). Le premier parcours remonte les ancêtres du nœud de départ pour trouver les
révisions racines (les "\en{initial commits}") du projet, puis un deuxième parcours est lancé dans l'autre
sens avec des marqueurs de niveau depuis chacune de ces révisions racines afin de trouver tous les nœuds
\texttt{ORI} qui peuvent les atteindre et sont donc des \en{forks} les uns des autres. Pour chaque composante
connexe, seul un nœud \texttt{SNP} est retenu pour l'analyse en deuxième étape : celui étant le point de
départ de la plus longue chaîne de \englpl{commit} possible, donc ayant le plus de données exploitables.

Dans un deuxième temps, la fonction \texttt{collectProject} est appelée sur chaque projet retenu afin d'en
extraire les données de recherche. Cette fonction commence par identifier la branche ayant le plus de chance
d'être la branche principale du projet (voir la table de priorité \texttt{mainBranchScore} ligne 623), puis
démarre un parcours largeur à partir de cette branche dans lequel elle compte :

\begin{itemize}
    \item le nombre de contributeurs pendant la période de référence n'ayant jamais contribué dans ce projet
        avant (variable expliquée) ;
    \item le nombre de contributeurs uniques pendant une période récente avant la période de référence
        (variable expliquative, hypothèse H\ref{hyp:recentcontributorcount}) ;
    \item le nombre de \englpl{commit} dans la même période récente avant la période de référence (variable
        expliquative, hypothèse H\ref{hyp:recentcommitcount}).
\end{itemize}

La présence d'instructions de contribution (hypothèse H\ref{hyp:contributionguidelines}) est plus compliquée à
vérifier. Le graphe possédant le nom et la hierarchie des fichiers contenus dans chaque \engl{commit}, mais
pas leur contenu, l'analyse se contente de vérifier si un fichier dont le nom est une variante du classique
\texttt{CONTRIBUTING.md} existe. Si ce fichier existe, l'analyse conclue que le projet possède effectivement
des instructions de contribution, sinon, elle vérifie la présence d'un fichier dont le nom est une variante du
classique \texttt{README.md}. Si ce fichier existe, l'analyse conclue que le projet possède \emph{peut être}
des instructions de contribution et construie l'URL à laquelle un traitement ultérieur pourra télécharger le
contenu du fichier \texttt{README} et y confirmer ou non la présence d'instructions de contribution (décrit en
section \ref{sec:collectreadme}). Si aucun de ces deux types de fichier n'existe, l'analyse conclue que le
projet ne possède pas d'instructions de contribution.

Enfin, les données collectées sont affichées sur la sortie standard sous la forme d'un fichier CSV.

\section{Collecte complémentaire des données}
\label{sec:collectreadme}

Le code (un script Python) est disponible en annexe \ref{app:checkreadme.py}.

\todo[inline]{Décrire le script.}

\section{Traitement des données}

Le code (un script Python) est disponible en annexe \ref{app:analysis.py}.

\todo[inline]{Décrire la méthodologie.}

\todo[inline]{%
    TODO bonus : faire un "\en{replication package}" avec mon code, comme le font \textcite{swh-graph-2020}
    ici : \url{https://zenodo.org/record/3574459} ?%
}
